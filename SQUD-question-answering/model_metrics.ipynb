{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Metrics\n",
    "\n",
    "We've put together our first Q&A model. In this notebook we're going to merge both of these and measure our Q&A model performance on the SQuAD 2.0 validation set as a whole.\n",
    "\n",
    "First, we load our SQuAD validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/squad/dev.json', 'r') as f:\n",
    "    squad = json.load(f)\n",
    "\n",
    "# we will limit it to the first 100 samples in the interest of time\n",
    "squad_min = squad[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bpakra200/opt/anaconda3/envs/drexel/lib/python3.10/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(host='localhost', username='', password='', index='squad_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of contexts (we cannot do this using current dictionary format)\n",
    "contexts = [sample['context'] for sample in squad_min]\n",
    "\n",
    "# convert to set to remove duplicates, then back to list\n",
    "contexts = list(set(contexts))\n",
    "\n",
    "# convert back to dictionary format we need\n",
    "squad_docs_min = [{'content': sample} for sample in contexts]\n",
    "squad_min =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(squad_docs_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(squad_docs_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 106,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "res = requests.get('http://localhost:9200/squad_mini/_count')\n",
    "\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's setup the QA pipeline again using the `deepset/bert-base-cased-squad2` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bpakra200/opt/anaconda3/envs/drexel/lib/python3.10/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "\n",
    "doc_store = ElasticsearchDocumentStore(\n",
    "    host='localhost',\n",
    "    username='', password='',\n",
    "    index='squad_mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import BM25Retriever\n",
    "from haystack.nodes import FARMReader\n",
    "\n",
    "retriever = BM25Retriever(doc_store)  # BM25\n",
    "reader = FARMReader(model_name_or_path='deepset/bert-base-cased-squad2',\n",
    "                    context_window_size=1500,\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "qa = ExtractiveQAPipeline(reader=reader, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bpakra200/opt/anaconda3/envs/drexel/lib/python3.10/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'King Ethelred II of England'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = qa.run(query='Who did Emma Marry?')\n",
    "ans['answers'][0].answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we build a list of predicted answers `model_out` and true answers `reference` and calculate the ROUGE score based on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.62s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.98s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:07<00:00,  7.07s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.98s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.92s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.92s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.05s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.96s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  3.00s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:06<00:00,  6.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.15s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.89s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.96s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.92s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.74s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.01s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.79s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.65s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.00s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.02s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.95s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.94s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.98s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.92s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.94s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.95s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.62s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.01s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.05s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:07<00:00,  7.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:05<00:00,  5.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.79s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.74s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.92s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.65s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.15s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.11s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.11s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.81s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.95s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.09s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.08s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.15s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.65s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.07s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.89s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.08s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.05s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.89s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:05<00:00,  5.06s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.62s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.02s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.06s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.15s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.79s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.62s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.65s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:08<00:00,  8.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.15s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.11s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.08s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.04s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.36s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.09s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.01s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.94s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.11s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.81s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.98s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.65s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.21s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.74s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.45s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.33s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.29s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.40s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.05s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.96s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.79s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.94s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.96s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.02s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.94s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.20s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.05s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.09s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.91s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.81s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.65s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.66s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.09s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.15s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.95s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.02s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.81s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.86s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.74s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.81s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.03s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.96s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.13s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.72s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.42s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.16s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.07s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.89s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.97s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.92s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.01s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.73s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.46s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.78s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.44s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.51s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.68s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.48s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.50s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.94s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.90s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:05<00:00,  5.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.96s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.17s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.23s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.09s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.43s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.09s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.60s/ Batches]\n",
      "100%|██████████| 1000/1000 [44:56<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model_out = []\n",
    "reference = []\n",
    "\n",
    "for pair in tqdm(squad_min, leave=True):\n",
    "    ans = qa.run(\n",
    "        query= pair['question']\n",
    "       \n",
    "    )\n",
    "    # append the prediction and reference to the respective lists\n",
    "    model_out.append(ans['answers'][0].answer)\n",
    "    reference.append(pair['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model_out\", \"wb\") as fp:\n",
    "    pickle.dump(model_out, fp)\n",
    "with open(\"reference\", \"wb\") as fp:\n",
    "    pickle.dump(reference, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"model_out\", \"rb\") as fp:   # Unpickling\n",
    "   model_out = pickle.load(fp)\n",
    "with open(\"reference\", \"rb\") as fp:   # Unpickling\n",
    "   reference = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This make take some time to process. The processing speed of our models will improve as we begin using more efficient implementations over the next few sections.\n",
    "\n",
    "Once that has finished processing, we can calculate our ROUGE scores just like we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rouge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrouge\u001b[39;00m \u001b[39mimport\u001b[39;00m Rouge\n\u001b[1;32m      3\u001b[0m \u001b[39m# initialize\u001b[39;00m\n\u001b[1;32m      4\u001b[0m rouge \u001b[39m=\u001b[39m Rouge()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge'"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# initialize\n",
    "rouge = Rouge()\n",
    "\n",
    "# get scores\n",
    "rouge.get_scores(model_out, reference, avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't seem to be scoring as high as we would expect, if we print some of the results we can see why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollo,  |  Rollo  |  0.0\n",
      "\"Norseman, Viking\".  |  Norseman, Viking  |  0.0\n"
     ]
    }
   ],
   "source": [
    "# recalculate individual scores\n",
    "scores = rouge.get_scores(model_out, reference)\n",
    "\n",
    "print(model_out[4], ' | ', reference[4], ' | ', scores[4]['rouge-1']['f'])\n",
    "print(model_out[22], ' | ', reference[22], ' | ', scores[22]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the punctuation differences are causing our ROUGE score to view these words as not matching. To fix this, we'll import `re` and remove any characters that are not spaces, letters, or numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "clean = re.compile('(?i)[^0-9a-z ]')\n",
    "\n",
    "# apply this to both lists\n",
    "model_out = [clean.sub('', text) for text in model_out]\n",
    "reference = [clean.sub('', text) for text in reference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate individual scores\n",
    "scores = rouge.get_scores(model_out, reference)\n",
    "\n",
    "print(model_out[4], ' | ', reference[4], ' | ', scores[4]['rouge-1']['f'])\n",
    "print(model_out[22], ' | ', reference[22], ' | ', scores[22]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores are looking better now, let's calculate the average again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge.get_scores(model_out, reference, avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are seeing much more realistic scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drexel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
